# NewsMind 真实新闻获取使用指南

## 📰 概述

NewsMind 现在支持从真实网站获取新闻，包括国内外主流新闻源。系统会自动爬取最新新闻并存储到数据库中，用户可以通过前端界面查看和分析这些新闻。

## 🚀 快速开始

### 1. 启动系统

```bash
# Windows 一键启动
start_news_system.bat

# 或手动启动
# 后端
cd backend && python start_server.py

# 前端
cd frontend && npm run dev
```

### 2. 爬取新闻

```bash
# 使用简化爬虫（推荐）
python scripts/simple_news_crawler.py

# 使用管理工具
python scripts/manage_news.py
```

## 📊 新闻源配置

### 当前支持的新闻源

| 名称 | 类型 | 分类 | 状态 |
|------|------|------|------|
| CNN | RSS | 国际 | ✅ 活跃 |
| BBC News | RSS | 国际 | ✅ 活跃 |
| TechCrunch | RSS | 科技 | ✅ 活跃 |
| 36氪 | RSS | 科技 | ✅ 活跃 |
| 钛媒体 | RSS | 科技 | ✅ 活跃 |
| 新浪新闻 | API | 综合 | ✅ 活跃 |
| 腾讯新闻 | RSS | 综合 | ✅ 活跃 |
| 网易新闻 | RSS | 综合 | ✅ 活跃 |
| 凤凰网 | RSS | 综合 | ✅ 活跃 |
| 澎湃新闻 | RSS | 综合 | ✅ 活跃 |
| 虎嗅网 | RSS | 科技 | ✅ 活跃 |

### 添加新新闻源

1. 编辑 `scripts/check_news_sources.py`
2. 在 `real_sources` 列表中添加新源
3. 运行脚本更新数据库

```python
{
    'name': '新新闻源',
    'url': 'https://example.com/rss.xml',
    'type': 'rss',  # 或 'api'
    'category': '分类',
    'is_active': 1
}
```

## 🛠️ 管理工具

### 新闻管理工具

运行 `python scripts/manage_news.py` 进入交互式管理界面：

```
NewsMind 新闻管理工具
============================================================
1. 查看新闻源
2. 查看文章统计
3. 爬取最新新闻
4. 查看最新文章
5. 清理旧文章
6. 退出
============================================================
```

### 功能说明

- **查看新闻源**: 显示所有配置的新闻源及其状态
- **查看文章统计**: 显示文章总数、分类统计、来源统计
- **爬取最新新闻**: 自动爬取所有活跃新闻源的最新文章
- **查看最新文章**: 显示最近20篇文章的详细信息
- **清理旧文章**: 删除7天前的旧文章（可选）

## 📈 数据统计

### 文章统计API

```bash
# 获取统计信息
curl http://localhost:8000/api/v1/news/statistics

# 响应示例
{
    "active_sources": 13,
    "processed_articles": 0,
    "total_articles": 40
}
```

### 文章列表API

```bash
# 获取文章列表
curl http://localhost:8000/api/v1/news/articles

# 搜索文章
curl "http://localhost:8000/api/v1/news/search?q=关键词"
```

## 🔧 技术实现

### 爬虫架构

1. **简化爬虫** (`scripts/simple_news_crawler.py`)
   - 使用系统Python，无需额外依赖
   - 支持RSS源解析
   - 自动去重和内容清理

2. **增强爬虫** (`scripts/real_news_crawler.py`)
   - 支持多种新闻源类型
   - 需要安装 `requests` 和 `feedparser`
   - 更强大的内容解析能力

### 数据存储

- **数据库**: SQLite (`newsmind.db`)
- **表结构**: 
  - `news_sources`: 新闻源配置
  - `news_articles`: 文章数据
- **去重机制**: 基于URL去重

### 内容处理

- **HTML清理**: 自动移除HTML标签
- **内容截断**: 限制内容长度（1000字符）
- **语言检测**: 自动识别中英文
- **时间解析**: 支持多种时间格式

## 🚨 注意事项

### 网络问题

- 部分新闻源可能因网络问题无法访问
- 建议定期检查新闻源状态
- 可配置代理或更换新闻源

### 内容限制

- 遵守网站的robots.txt规则
- 合理控制爬取频率
- 仅用于学习和研究目的

### 数据维护

- 定期清理旧文章
- 监控数据库大小
- 备份重要数据

## 🔄 自动化

### 定时爬取

可以设置定时任务自动爬取新闻：

```bash
# Windows 计划任务
schtasks /create /tn "NewsMind Crawler" /tr "python scripts/simple_news_crawler.py" /sc daily /st 08:00

# Linux crontab
0 8 * * * cd /path/to/newsmind && python scripts/simple_news_crawler.py
```

### 监控脚本

创建监控脚本检查系统状态：

```bash
# 检查服务状态
curl -f http://localhost:8000/health || echo "后端服务异常"

# 检查文章数量
python -c "import sqlite3; conn=sqlite3.connect('newsmind.db'); print(conn.execute('SELECT COUNT(*) FROM news_articles').fetchone()[0])"
```

## 📞 故障排除

### 常见问题

1. **爬虫失败**
   - 检查网络连接
   - 验证新闻源URL
   - 查看错误日志

2. **数据库错误**
   - 检查数据库文件权限
   - 验证表结构
   - 备份并重建数据库

3. **服务启动失败**
   - 检查端口占用
   - 验证依赖安装
   - 查看启动日志

### 日志文件

- 后端日志: `backend/logs/newsmind.log`
- 爬虫日志: 控制台输出
- 错误信息: 各脚本的错误输出

## 🎯 最佳实践

1. **定期维护**
   - 每周运行一次爬虫
   - 每月清理旧文章
   - 定期检查新闻源状态

2. **性能优化**
   - 限制单次爬取数量
   - 使用缓存减少重复请求
   - 优化数据库查询

3. **内容质量**
   - 定期更新新闻源
   - 过滤低质量内容
   - 保持内容多样性

## 📚 相关文档

- [项目总体总结](../08-项目总体总结.md)
- [API文档](http://localhost:8000/docs)
- [前端使用指南](../前端使用指南.md)
- [部署指南](../部署指南.md)

---

*最后更新: 2025-07-09* 