#!/usr/bin/env python3
"""
ä¿®å¤è¯­è¨€æ ‡è¯†é—®é¢˜ V2 - åŸºäºæ–°é—»æºåç§°çš„å‡†ç¡®è¯­è¨€æ£€æµ‹
"""
import sqlite3
import re
from datetime import datetime

def detect_language_by_source(source_name):
    """åŸºäºæ–°é—»æºåç§°æ£€æµ‹è¯­è¨€"""
    # åŸºäºæ–°é—»æºåç§°çš„è¯­è¨€æ˜ å°„
    language_mapping = {
        # è‹±è¯­æ–°é—»æº
        'en': [
            'CNN', 'BBC News', 'Reuters', 'TechCrunch', 'Bloomberg', 
            'The Guardian', 'The New York Times', 'NYTimes', 'NPR News', 
            'Ars Technica', 'Wired', 'Google News China', 'VentureBeat AI', 
            'Al Jazeera', 'RT News', 'Sputnik', 'Foreign Policy'
        ],
        
        # æ—¥è¯­æ–°é—»æº
        'ja': [
            'NHK News', 'æœæ—¥æ–°é—»', 'è¯»å–æ–°é—»', 'æ—¥æœ¬ç»æµæ–°é—»'
        ],
        
        # éŸ©è¯­æ–°é—»æº
        'ko': [
            'éŸ©å›½ä¸­å¤®æ—¥æŠ¥', 'éŸ©å›½ç»æµæ—¥æŠ¥'
        ],
        
        # ä¸­æ–‡æ–°é—»æº
        'zh': [
            'æ–°æµªæ–°é—»', 'è…¾è®¯æ–°é—»', 'ç½‘æ˜“æ–°é—»', 'å‡¤å‡°ç½‘', 'æ¾æ¹ƒæ–°é—»', 
            '36æ°ª', 'è™å—…ç½‘', 'é’›åª’ä½“', 'æ–°åŠ å¡æ—©æŠ¥', 'å¾·å›½ä¹‹å£°ä¸­æ–‡', 
            'è”åˆå›½æ–°é—»'
        ],
        
        # æ³•è¯­æ–°é—»æº
        'fr': [
            'Le Monde', 'France 24'
        ],
        
        # å¾·è¯­æ–°é—»æº
        'de': [
            'Deutsche Welle', 'å¾·å›½ä¹‹å£°'
        ],
        
        # æ„å¤§åˆ©è¯­æ–°é—»æº
        'it': [
            'Corriere della Sera', 'La Repubblica'
        ],
        
        # è¥¿ç­ç‰™è¯­æ–°é—»æº
        'es': [
            'El PaÃ­s', 'El Mundo'
        ],
        
        # ä¿„è¯­æ–°é—»æº
        'ru': [
            'RT News', 'Sputnik'
        ]
    }
    
    # æŸ¥æ‰¾åŒ¹é…çš„è¯­è¨€
    for lang, sources in language_mapping.items():
        if source_name in sources:
            return lang
    
    # é»˜è®¤è‹±è¯­
    return 'en'

def detect_language_by_content(title, content):
    """åŸºäºå†…å®¹ç‰¹å¾æ£€æµ‹è¯­è¨€ï¼ˆè¾…åŠ©æ–¹æ³•ï¼‰"""
    if not title:
        return 'en'
    
    text = (title + " " + (content or "")).lower()
    
    # æ—¥è¯­ç‰¹å¾æ£€æµ‹ï¼ˆå¹³å‡åã€ç‰‡å‡åã€æ±‰å­—ï¼‰
    japanese_chars = re.findall(r'[\u3040-\u309f\u30a0-\u30ff\u4e00-\u9faf]', text)
    if len(japanese_chars) > len(text) * 0.15:
        return 'ja'
    
    # éŸ©è¯­ç‰¹å¾æ£€æµ‹
    korean_chars = re.findall(r'[\uac00-\ud7af]', text)
    if len(korean_chars) > len(text) * 0.15:
        return 'ko'
    
    # ä¸­æ–‡ç‰¹å¾æ£€æµ‹
    chinese_chars = re.findall(r'[\u4e00-\u9fff]', text)
    if len(chinese_chars) > len(text) * 0.4:
        return 'zh'
    
    # ä¿„è¯­ç‰¹å¾æ£€æµ‹
    russian_chars = re.findall(r'[\u0400-\u04ff]', text)
    if len(russian_chars) > len(text) * 0.15:
        return 'ru'
    
    # é˜¿æ‹‰ä¼¯è¯­ç‰¹å¾æ£€æµ‹
    arabic_chars = re.findall(r'[\u0600-\u06ff]', text)
    if len(arabic_chars) > len(text) * 0.15:
        return 'ar'
    
    # é»˜è®¤è‹±è¯­
    return 'en'

def fix_language_identification():
    """ä¿®å¤è¯­è¨€æ ‡è¯†é—®é¢˜"""
    print("ğŸ”§ ä¿®å¤è¯­è¨€æ ‡è¯†é—®é¢˜ V2...")
    print("=" * 60)
    
    conn = sqlite3.connect("backend/newsmind.db")
    cursor = conn.cursor()
    
    try:
        # è·å–æ‰€æœ‰æ–‡ç« 
        cursor.execute("""
            SELECT id, title, content, original_language, source_name 
            FROM news_articles 
            ORDER BY id
        """)
        
        articles = cursor.fetchall()
        fixed_count = 0
        language_changes = {}
        
        for article in articles:
            article_id, title, content, current_language, source_name = article
            
            # é¦–å…ˆåŸºäºæ–°é—»æºåç§°æ£€æµ‹è¯­è¨€
            source_language = detect_language_by_source(source_name)
            
            # å¦‚æœæ–°é—»æºæ— æ³•ç¡®å®šï¼Œåˆ™åŸºäºå†…å®¹æ£€æµ‹
            if source_language == 'en':
                content_language = detect_language_by_content(title, content)
                # åªæœ‰å½“å†…å®¹æ£€æµ‹ç»“æœä¸æ˜¯è‹±è¯­æ—¶ï¼Œæ‰ä½¿ç”¨å†…å®¹æ£€æµ‹ç»“æœ
                if content_language != 'en':
                    correct_language = content_language
                else:
                    correct_language = 'en'
            else:
                correct_language = source_language
            
            # å¦‚æœè¯­è¨€æ ‡è¯†ä¸æ­£ç¡®ï¼Œè¿›è¡Œä¿®å¤
            if current_language != correct_language:
                print(f"  ğŸ”„ æ–‡ç«  {article_id}: {current_language} â†’ {correct_language}")
                print(f"      æ ‡é¢˜: {title[:50]}...")
                print(f"      æ¥æº: {source_name}")
                
                # æ›´æ–°è¯­è¨€æ ‡è¯†
                cursor.execute("""
                    UPDATE news_articles 
                    SET original_language = ?, 
                        is_title_translated = FALSE,
                        is_content_translated = FALSE,
                        translated_title = NULL,
                        translated_content = NULL
                    WHERE id = ?
                """, (correct_language, article_id))
                
                fixed_count += 1
                
                # ç»Ÿè®¡è¯­è¨€å˜åŒ–
                if correct_language not in language_changes:
                    language_changes[correct_language] = 0
                language_changes[correct_language] += 1
        
        conn.commit()
        
        print(f"\nâœ… è¯­è¨€æ ‡è¯†ä¿®å¤å®Œæˆ!")
        print(f"   ä¿®å¤æ–‡ç« æ•°: {fixed_count}")
        
        if language_changes:
            print("\nğŸ“Š è¯­è¨€å˜åŒ–ç»Ÿè®¡:")
            for lang, count in language_changes.items():
                lang_emoji = {
                    'en': 'ğŸ‡ºğŸ‡¸', 'ja': 'ğŸ‡¯ğŸ‡µ', 'ko': 'ğŸ‡°ğŸ‡·', 'zh': 'ğŸ‡¨ğŸ‡³',
                    'fr': 'ğŸ‡«ğŸ‡·', 'de': 'ğŸ‡©ğŸ‡ª', 'it': 'ğŸ‡®ğŸ‡¹', 'es': 'ğŸ‡ªğŸ‡¸', 'ru': 'ğŸ‡·ğŸ‡º'
                }.get(lang, 'ğŸŒ')
                print(f"   {lang_emoji} {lang}: {count} ç¯‡")
        
        # æ˜¾ç¤ºæœ€ç»ˆè¯­è¨€åˆ†å¸ƒ
        show_final_language_distribution(cursor)
        
    except Exception as e:
        print(f"âŒ ä¿®å¤å¤±è´¥: {e}")
        conn.rollback()
    finally:
        conn.close()

def show_final_language_distribution(cursor):
    """æ˜¾ç¤ºæœ€ç»ˆè¯­è¨€åˆ†å¸ƒ"""
    print("\nğŸ“Š æœ€ç»ˆè¯­è¨€åˆ†å¸ƒ:")
    print("-" * 40)
    
    cursor.execute("""
        SELECT original_language, COUNT(*) as count 
        FROM news_articles 
        GROUP BY original_language 
        ORDER BY count DESC
    """)
    
    for lang, count in cursor.fetchall():
        lang_emoji = {
            'en': 'ğŸ‡ºğŸ‡¸', 'ja': 'ğŸ‡¯ğŸ‡µ', 'ko': 'ğŸ‡°ğŸ‡·', 'zh': 'ğŸ‡¨ğŸ‡³',
            'fr': 'ğŸ‡«ğŸ‡·', 'de': 'ğŸ‡©ğŸ‡ª', 'it': 'ğŸ‡®ğŸ‡¹', 'es': 'ğŸ‡ªğŸ‡¸', 'ru': 'ğŸ‡·ğŸ‡º'
        }.get(lang, 'ğŸŒ')
        print(f"{lang_emoji} {lang}: {count} ç¯‡")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒ æ–°é—»è¯­è¨€æ ‡è¯†ä¿®å¤å·¥å…· V2")
    print("=" * 60)
    
    fix_language_identification()
    
    print("\nğŸ¯ ä¸‹ä¸€æ­¥:")
    print("   1. è¿è¡Œç¿»è¯‘è„šæœ¬é‡æ–°ç¿»è¯‘éä¸­æ–‡æ–‡ç« ")
    print("   2. éªŒè¯ç¿»è¯‘è´¨é‡")
    print("   3. æµ‹è¯•å‰ç«¯æ˜¾ç¤ºæ•ˆæœ")

if __name__ == "__main__":
    main() 