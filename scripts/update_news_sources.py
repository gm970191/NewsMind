#!/usr/bin/env python3
"""
æ›´æ–°æ–°é—»æºé…ç½®
åˆ é™¤æ— æ•ˆæ–°é—»æºï¼Œæ·»åŠ é«˜è´¨é‡çœŸå®æ–°é—»æº
"""
import sqlite3
from datetime import datetime

def update_news_sources():
    """æ›´æ–°æ–°é—»æºé…ç½®"""
    print("ğŸ”„ å¼€å§‹æ›´æ–°æ–°é—»æºé…ç½®...")
    print("=" * 60)
    
    conn = sqlite3.connect("backend/newsmind.db")
    cursor = conn.cursor()
    
    try:
        # æ¸…ç©ºç°æœ‰æ–°é—»æº
        cursor.execute("DELETE FROM news_sources")
        print("ğŸ—‘ï¸  å·²æ¸…ç©ºç°æœ‰æ–°é—»æº")
        
        # å®šä¹‰é«˜è´¨é‡æ–°é—»æº
        high_quality_sources = [
            # è‹±è¯­ç±»ä¸»æµæ–°é—»ç½‘ç«™
            ("BBC News", "https://feeds.bbci.co.uk/news/rss.xml", "rss", "å›½é™…", 1),
            ("CNN", "https://rsshub.app/cnn", "rss", "å›½é™…", 1),
            ("Reuters", "https://www.reutersagency.com/feed/", "rss", "å›½é™…", 1),
            ("The Guardian", "https://www.theguardian.com/world/rss", "rss", "å›½é™…", 1),
            ("NYTimes", "https://rss.nytimes.com/services/xml/rss/nyt/HomePage.xml", "rss", "å›½é™…", 1),
            ("Al Jazeera", "https://www.aljazeera.com/xml/rss/all.xml", "rss", "å›½é™…", 1),
            ("The Washington Post", "https://feeds.washingtonpost.com/rss/world", "rss", "å›½é™…", 1),
            
            # éè‹±è¯­æ–°é—»ç½‘ç«™
            ("NHK News", "https://www3.nhk.or.jp/rss/news/cat0.xml", "rss", "å›½é™…", 1),
            ("æœæ—¥æ–°é—»", "https://www.asahi.com/rss/asahi/newsheadlines.rdf", "rss", "å›½é™…", 1),
            ("å¾·å›½ä¹‹å£°ä¸­æ–‡", "https://rss.dw.com/rdf/rss-chi-all", "rss", "å›½é™…", 1),
            ("Le Monde", "https://www.lemonde.fr/rss/une.xml", "rss", "å›½é™…", 1),
            ("RT News", "https://www.rt.com/rss/news/", "rss", "å›½é™…", 1),
            ("Sputnik", "https://sputniknews.com/export/rss2/index.xml", "rss", "å›½é™…", 1),
            ("è”åˆå›½æ–°é—»", "https://news.un.org/feed/subscribe/zh/news/all/rss.xml", "rss", "å›½é™…", 1),
            
            # é«˜è´¨é‡ä¸“é¢˜ç±»
            ("Google News China", "https://news.google.com/rss/search?q=China", "rss", "å›½é™…", 1),
            ("TechCrunch", "https://techcrunch.com/feed/", "rss", "ç§‘æŠ€", 1),
            ("VentureBeat AI", "https://venturebeat.com/category/ai/feed/", "rss", "ç§‘æŠ€", 1),
            ("Foreign Policy", "https://foreignpolicy.com/feed/", "rss", "æ”¿æ²»", 1),
            ("Defense News", "https://www.defensenews.com/arc/outboundfeeds/rss/", "rss", "å†›äº‹", 1),
        ]
        
        # æ’å…¥é«˜è´¨é‡æ–°é—»æº
        for name, url, source_type, category, is_active in high_quality_sources:
            cursor.execute("""
                INSERT INTO news_sources (name, url, type, category, is_active, created_at, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (name, url, source_type, category, is_active, datetime.now().isoformat(), datetime.now().isoformat()))
            print(f"âœ… æ·»åŠ : {name} - {url}")
        
        conn.commit()
        print(f"\nğŸ“Š æ›´æ–°å®Œæˆï¼Œå…±æ·»åŠ  {len(high_quality_sources)} ä¸ªé«˜è´¨é‡æ–°é—»æº")
        
        # æ˜¾ç¤ºæ›´æ–°åçš„æ–°é—»æº
        cursor.execute("SELECT id, name, url, type, category FROM news_sources WHERE is_active=1 ORDER BY id")
        sources = cursor.fetchall()
        print(f"\nğŸ“‹ å½“å‰æ´»è·ƒæ–°é—»æºåˆ—è¡¨:")
        print("-" * 60)
        for source_id, name, url, source_type, category in sources:
            print(f"ID: {source_id:2d} | {name:20s} | {category:6s} | {source_type:4s} | {url}")
        
    except Exception as e:
        print(f"âŒ æ›´æ–°å¤±è´¥: {e}")
        conn.rollback()
    finally:
        conn.close()

if __name__ == '__main__':
    update_news_sources() 