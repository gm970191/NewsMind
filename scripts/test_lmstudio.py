#!/usr/bin/env python3
"""
ç‹¬ç«‹æµ‹è¯•æœ¬åœ°LM Studioå¤§æ¨¡å‹
"""
import requests
import json
import time
from typing import Optional, Dict, Any
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class LMStudioLLM:
    """æœ¬åœ°LM Studioå¤§æ¨¡å‹è°ƒç”¨ç±»"""
    
    def __init__(self, api_url: str = "http://127.0.0.1:1234/v1/chat/completions"):
        self.api_url = api_url
        self.timeout = 30
    
    def test_connection(self) -> bool:
        """æµ‹è¯•è¿æ¥å¯ç”¨æ€§"""
        try:
            logger.info(f"ğŸ” æµ‹è¯•è¿æ¥: {self.api_url}")
            # ç›´æ¥æµ‹è¯•APIç«¯ç‚¹ï¼Œä¸ä½¿ç”¨healthç«¯ç‚¹
            response = requests.get(self.api_url.replace("/v1/chat/completions", ""), timeout=5)
            if response.status_code in [200, 404, 405]:  # è¿™äº›çŠ¶æ€ç è¡¨ç¤ºæœåŠ¡åœ¨è¿è¡Œ
                logger.info("âœ… è¿æ¥æµ‹è¯•æˆåŠŸ")
                return True
            else:
                logger.warning(f"âš ï¸  è¿æ¥æµ‹è¯•å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return False
        except Exception as e:
            logger.error(f"âŒ è¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
            return False
    
    def test_available(self) -> bool:
        """æµ‹è¯•APIå¯ç”¨æ€§"""
        try:
            logger.info("ğŸ§ª æµ‹è¯•APIå¯ç”¨æ€§...")
            data = {
                "model": "lmstudio",
                "messages": [
                    {"role": "system", "content": "ä½ æ˜¯AIåŠ©æ‰‹ã€‚"},
                    {"role": "user", "content": "ä½ å¥½"}
                ],
                "temperature": 0.1,
                "max_tokens": 10
            }
            
            response = requests.post(self.api_url, json=data, timeout=10)
            response.raise_for_status()
            
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                content = result['choices'][0]['message']['content']
                logger.info(f"âœ… APIæµ‹è¯•æˆåŠŸï¼Œå“åº”: {content}")
                return True
            else:
                logger.warning("âš ï¸  APIå“åº”æ ¼å¼å¼‚å¸¸")
                return False
                
        except Exception as e:
            logger.error(f"âŒ APIæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def call(self, system_prompt: str, user_content: str, max_tokens: int = 1000) -> Optional[str]:
        """è°ƒç”¨å¤§æ¨¡å‹"""
        try:
            data = {
                "model": "lmstudio",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_content}
                ],
                "temperature": 0.1,
                "max_tokens": max_tokens
            }
            
            logger.info(f"ğŸ¤– è°ƒç”¨å¤§æ¨¡å‹: {user_content[:50]}...")
            start_time = time.time()
            
            response = requests.post(self.api_url, json=data, timeout=self.timeout)
            response.raise_for_status()
            
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                content = result['choices'][0]['message']['content'].strip()
                elapsed = time.time() - start_time
                logger.info(f"âœ… è°ƒç”¨æˆåŠŸ ({elapsed:.2f}s): {content[:100]}...")
                return content
            else:
                logger.error("âŒ å“åº”æ ¼å¼å¼‚å¸¸")
                return None
                
        except Exception as e:
            logger.error(f"âŒ è°ƒç”¨å¤±è´¥: {e}")
            return None
    
    def test_translation(self) -> bool:
        """æµ‹è¯•ç¿»è¯‘åŠŸèƒ½"""
        logger.info("ğŸŒ æµ‹è¯•ç¿»è¯‘åŠŸèƒ½...")
        
        system_prompt = "å°†ä»¥ä¸‹è‹±æ–‡æ–°é—»æ ‡é¢˜ç¿»è¯‘æˆä¸­æ–‡ï¼Œä¿æŒåŸæ„ï¼Œä½¿ç”¨æµç•…çš„ä¸­æ–‡è¡¨è¾¾ã€‚ç›´æ¥è¿”å›ç¿»è¯‘ç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•æ ¼å¼ã€‚"
        user_content = "Chinese researchers unveil Memory Operating System for AI models"
        
        result = self.call(system_prompt, user_content)
        if result:
            logger.info(f"âœ… ç¿»è¯‘æµ‹è¯•æˆåŠŸ: {result}")
            return True
        else:
            logger.error("âŒ ç¿»è¯‘æµ‹è¯•å¤±è´¥")
            return False
    
    def test_summary(self) -> bool:
        """æµ‹è¯•æ‘˜è¦åŠŸèƒ½"""
        logger.info("ğŸ“ æµ‹è¯•æ‘˜è¦åŠŸèƒ½...")
        
        system_prompt = "ä¸ºä»¥ä¸‹æ–°é—»ç”Ÿæˆç®€æ´çš„ä¸­æ–‡æ‘˜è¦ï¼Œæ§åˆ¶åœ¨150å­—ä»¥å†…ï¼Œçªå‡ºæ ¸å¿ƒä¿¡æ¯ã€‚ç›´æ¥è¿”å›æ‘˜è¦å†…å®¹ã€‚"
        user_content = """
        Chinese researchers have developed a new Memory Operating System (MemOS) for AI models. 
        This system enables AI models to maintain long-term memory and context awareness, 
        similar to human memory processes. The technology could revolutionize how AI systems 
        handle complex, multi-step tasks and maintain context over extended periods.
        """
        
        result = self.call(system_prompt, user_content)
        if result:
            logger.info(f"âœ… æ‘˜è¦æµ‹è¯•æˆåŠŸ: {result}")
            return True
        else:
            logger.error("âŒ æ‘˜è¦æµ‹è¯•å¤±è´¥")
            return False
    
    def benchmark(self, num_calls: int = 3) -> Dict[str, Any]:
        """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        logger.info(f"âš¡ å¼€å§‹æ€§èƒ½åŸºå‡†æµ‹è¯• ({num_calls} æ¬¡è°ƒç”¨)...")
        
        system_prompt = "ä½ æ˜¯AIåŠ©æ‰‹ï¼Œè¯·ç®€å•å›å¤ã€‚"
        user_content = "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚"
        
        times = []
        success_count = 0
        
        for i in range(num_calls):
            start_time = time.time()
            result = self.call(system_prompt, user_content)
            elapsed = time.time() - start_time
            
            if result:
                times.append(elapsed)
                success_count += 1
                logger.info(f"  è°ƒç”¨ {i+1}: {elapsed:.2f}s")
            else:
                logger.warning(f"  è°ƒç”¨ {i+1}: å¤±è´¥")
            
            # é—´éš”1ç§’
            if i < num_calls - 1:
                time.sleep(1)
        
        if times:
            avg_time = sum(times) / len(times)
            min_time = min(times)
            max_time = max(times)
            
            benchmark_result = {
                "total_calls": num_calls,
                "success_count": success_count,
                "success_rate": success_count / num_calls * 100,
                "avg_time": avg_time,
                "min_time": min_time,
                "max_time": max_time,
                "times": times
            }
            
            logger.info(f"ğŸ“Š åŸºå‡†æµ‹è¯•ç»“æœ:")
            logger.info(f"  æ€»è°ƒç”¨: {num_calls}")
            logger.info(f"  æˆåŠŸ: {success_count}")
            logger.info(f"  æˆåŠŸç‡: {benchmark_result['success_rate']:.1f}%")
            logger.info(f"  å¹³å‡æ—¶é—´: {avg_time:.2f}s")
            logger.info(f"  æœ€å¿«: {min_time:.2f}s")
            logger.info(f"  æœ€æ…¢: {max_time:.2f}s")
            
            return benchmark_result
        else:
            logger.error("âŒ åŸºå‡†æµ‹è¯•å¤±è´¥ï¼Œæ— æˆåŠŸè°ƒç”¨")
            return {"error": "No successful calls"}


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("ğŸ§ª LM Studio æœ¬åœ°å¤§æ¨¡å‹æµ‹è¯•")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    llm = LMStudioLLM()
    
    # 1. APIå¯ç”¨æ€§æµ‹è¯•ï¼ˆåŒ…å«è¿æ¥æµ‹è¯•ï¼‰
    print("\n1ï¸âƒ£ APIå¯ç”¨æ€§æµ‹è¯•")
    if not llm.test_available():
        print("âŒ APIä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥LM Studioæ˜¯å¦å¯åŠ¨åœ¨ http://127.0.0.1:1234")
        print("ğŸ’¡ æç¤ºï¼šè¯·ç¡®ä¿LM Studioå·²å¯åŠ¨å¹¶é…ç½®äº†æ­£ç¡®çš„æ¨¡å‹")
        return
    
    # 2. åŠŸèƒ½æµ‹è¯•
    print("\n2ï¸âƒ£ åŠŸèƒ½æµ‹è¯•")
    translation_ok = llm.test_translation()
    summary_ok = llm.test_summary()
    
    if not translation_ok or not summary_ok:
        print("âŒ åŠŸèƒ½æµ‹è¯•å¤±è´¥")
        return
    
    # 3. æ€§èƒ½åŸºå‡†æµ‹è¯•
    print("\n3ï¸âƒ£ æ€§èƒ½åŸºå‡†æµ‹è¯•")
    benchmark_result = llm.benchmark(3)
    
    # 4. æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“‹ æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    print("âœ… APIå¯ç”¨æ€§: é€šè¿‡")
    print(f"âœ… ç¿»è¯‘åŠŸèƒ½: {'é€šè¿‡' if translation_ok else 'å¤±è´¥'}")
    print(f"âœ… æ‘˜è¦åŠŸèƒ½: {'é€šè¿‡' if summary_ok else 'å¤±è´¥'}")
    print(f"âœ… æ€§èƒ½æµ‹è¯•: æˆåŠŸç‡ {benchmark_result.get('success_rate', 0):.1f}%")
    print("\nğŸ‰ LM Studio æœ¬åœ°å¤§æ¨¡å‹æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    main() 