#!/usr/bin/env python3
"""
ä¿®å¤è¯­è¨€æ ‡è¯†é—®é¢˜ - è¯†åˆ«å¹¶æ­£ç¡®æ ‡è®°å¤šè¯­è¨€æ–‡ç« 
"""
import sqlite3
import re
from datetime import datetime

def detect_language_advanced(title, content, source_name):
    """é«˜çº§è¯­è¨€æ£€æµ‹"""
    if not title:
        return 'en'  # é»˜è®¤è‹±è¯­
    
    text = (title + " " + (content or "")).lower()
    
    # æ—¥è¯­ç‰¹å¾æ£€æµ‹
    japanese_chars = re.findall(r'[\u3040-\u309f\u30a0-\u30ff\u4e00-\u9faf]', text)
    if len(japanese_chars) > len(text) * 0.1:
        return 'ja'
    
    # éŸ©è¯­ç‰¹å¾æ£€æµ‹
    korean_chars = re.findall(r'[\uac00-\ud7af]', text)
    if len(korean_chars) > len(text) * 0.1:
        return 'ko'
    
    # ä¸­æ–‡ç‰¹å¾æ£€æµ‹
    chinese_chars = re.findall(r'[\u4e00-\u9fff]', text)
    if len(chinese_chars) > len(text) * 0.3:
        return 'zh'
    
    # æ³•è¯­ç‰¹å¾æ£€æµ‹
    french_words = ['le', 'la', 'les', 'de', 'du', 'des', 'et', 'est', 'sont', 'pour', 'avec', 'sur', 'dans', 'par', 'que', 'qui', 'ce', 'cette', 'ces', 'un', 'une', 'au', 'aux', 'en', 'se', 'ne', 'pas', 'plus', 'moins', 'trÃ¨s', 'bien', 'bon', 'bonne', 'nouveau', 'nouvelle', 'grand', 'grande', 'petit', 'petite']
    french_count = sum(1 for word in french_words if word in text.split())
    if french_count > 3:
        return 'fr'
    
    # å¾·è¯­ç‰¹å¾æ£€æµ‹
    german_words = ['der', 'die', 'das', 'und', 'ist', 'sind', 'fÃ¼r', 'mit', 'auf', 'von', 'zu', 'in', 'an', 'bei', 'nach', 'vor', 'Ã¼ber', 'unter', 'zwischen', 'hinter', 'neben', 'seit', 'wÃ¤hrend', 'wegen', 'trotz', 'ohne', 'gegen', 'um', 'durch', 'entlang', 'gegenÃ¼ber', 'jenseits', 'diesseits', 'auÃŸerhalb', 'innerhalb']
    german_count = sum(1 for word in german_words if word in text.split())
    if german_count > 3:
        return 'de'
    
    # æ„å¤§åˆ©è¯­ç‰¹å¾æ£€æµ‹
    italian_words = ['il', 'la', 'lo', 'gli', 'le', 'di', 'da', 'in', 'con', 'su', 'per', 'tra', 'fra', 'e', 'o', 'ma', 'se', 'che', 'chi', 'cui', 'quale', 'quali', 'quanto', 'quanta', 'quanti', 'quante', 'questo', 'questa', 'questi', 'queste', 'quello', 'quella', 'quelli', 'quelle', 'mio', 'mia', 'miei', 'mie', 'tuo', 'tua', 'tuoi', 'tue', 'suo', 'sua', 'suoi', 'sue']
    italian_count = sum(1 for word in italian_words if word in text.split())
    if italian_count > 3:
        return 'it'
    
    # ä¿„è¯­ç‰¹å¾æ£€æµ‹
    russian_chars = re.findall(r'[\u0400-\u04ff]', text)
    if len(russian_chars) > len(text) * 0.1:
        return 'ru'
    
    # é˜¿æ‹‰ä¼¯è¯­ç‰¹å¾æ£€æµ‹
    arabic_chars = re.findall(r'[\u0600-\u06ff]', text)
    if len(arabic_chars) > len(text) * 0.1:
        return 'ar'
    
    # åŸºäºæ–°é—»æºåç§°çš„è¯­è¨€æ˜ å°„
    language_mapping = {
        'en': ['CNN', 'BBC News', 'Reuters', 'TechCrunch', 'Bloomberg', 
               'The Guardian', 'The New York Times', 'NYTimes', 'NPR News', 'Ars Technica', 'Wired',
               'Google News China', 'VentureBeat AI', 'Al Jazeera', 'RT News', 'Sputnik'],
        'ja': ['NHK News', 'æœæ—¥æ–°é—»', 'è¯»å–æ–°é—»', 'æ—¥æœ¬ç»æµæ–°é—»'],
        'ko': ['éŸ©å›½ä¸­å¤®æ—¥æŠ¥', 'éŸ©å›½ç»æµæ—¥æŠ¥'],
        'zh': ['æ–°æµªæ–°é—»', 'è…¾è®¯æ–°é—»', 'ç½‘æ˜“æ–°é—»', 'å‡¤å‡°ç½‘', 'æ¾æ¹ƒæ–°é—»', '36æ°ª', 'è™å—…ç½‘', 'é’›åª’ä½“', 'æ–°åŠ å¡æ—©æŠ¥', 'å¾·å›½ä¹‹å£°ä¸­æ–‡', 'è”åˆå›½æ–°é—»'],
        'fr': ['Le Monde', 'France 24'],
        'de': ['Deutsche Welle', 'å¾·å›½ä¹‹å£°'],
        'it': ['Corriere della Sera', 'La Repubblica'],
        'es': ['El PaÃ­s', 'El Mundo'],
        'ru': ['RT News', 'Sputnik']
    }
    
    # é¦–å…ˆåŸºäºæ–°é—»æºåç§°åˆ¤æ–­
    for lang, sources in language_mapping.items():
        if source_name in sources:
            return lang
    
    # é»˜è®¤è‹±è¯­
    return 'en'

def fix_language_identification():
    """ä¿®å¤è¯­è¨€æ ‡è¯†é—®é¢˜"""
    print("ğŸ”§ ä¿®å¤è¯­è¨€æ ‡è¯†é—®é¢˜...")
    print("=" * 60)
    
    conn = sqlite3.connect("backend/newsmind.db")
    cursor = conn.cursor()
    
    try:
        # è·å–æ‰€æœ‰æ–‡ç« 
        cursor.execute("""
            SELECT id, title, content, original_language, source_name 
            FROM news_articles 
            ORDER BY id
        """)
        
        articles = cursor.fetchall()
        fixed_count = 0
        language_changes = {}
        
        for article in articles:
            article_id, title, content, current_language, source_name = article
            
            # æ£€æµ‹æ­£ç¡®çš„è¯­è¨€
            correct_language = detect_language_advanced(title, content, source_name)
            
            # å¦‚æœè¯­è¨€æ ‡è¯†ä¸æ­£ç¡®ï¼Œè¿›è¡Œä¿®å¤
            if current_language != correct_language:
                print(f"  ğŸ”„ æ–‡ç«  {article_id}: {current_language} â†’ {correct_language}")
                print(f"      æ ‡é¢˜: {title[:50]}...")
                print(f"      æ¥æº: {source_name}")
                
                # æ›´æ–°è¯­è¨€æ ‡è¯†
                cursor.execute("""
                    UPDATE news_articles 
                    SET original_language = ?, 
                        is_title_translated = FALSE,
                        is_content_translated = FALSE,
                        translated_title = NULL,
                        translated_content = NULL
                    WHERE id = ?
                """, (correct_language, article_id))
                
                fixed_count += 1
                
                # ç»Ÿè®¡è¯­è¨€å˜åŒ–
                if correct_language not in language_changes:
                    language_changes[correct_language] = 0
                language_changes[correct_language] += 1
        
        conn.commit()
        
        print(f"\nâœ… è¯­è¨€æ ‡è¯†ä¿®å¤å®Œæˆ!")
        print(f"   ä¿®å¤æ–‡ç« æ•°: {fixed_count}")
        
        if language_changes:
            print("\nğŸ“Š è¯­è¨€å˜åŒ–ç»Ÿè®¡:")
            for lang, count in language_changes.items():
                lang_emoji = {
                    'en': 'ğŸ‡ºğŸ‡¸', 'ja': 'ğŸ‡¯ğŸ‡µ', 'ko': 'ğŸ‡°ğŸ‡·', 'zh': 'ğŸ‡¨ğŸ‡³',
                    'fr': 'ğŸ‡«ğŸ‡·', 'de': 'ğŸ‡©ğŸ‡ª', 'it': 'ğŸ‡®ğŸ‡¹', 'es': 'ğŸ‡ªğŸ‡¸', 'ru': 'ğŸ‡·ğŸ‡º'
                }.get(lang, 'ğŸŒ')
                print(f"   {lang_emoji} {lang}: {count} ç¯‡")
        
        # æ˜¾ç¤ºæœ€ç»ˆè¯­è¨€åˆ†å¸ƒ
        show_final_language_distribution(cursor)
        
    except Exception as e:
        print(f"âŒ ä¿®å¤å¤±è´¥: {e}")
        conn.rollback()
    finally:
        conn.close()

def show_final_language_distribution(cursor):
    """æ˜¾ç¤ºæœ€ç»ˆè¯­è¨€åˆ†å¸ƒ"""
    print("\nğŸ“Š æœ€ç»ˆè¯­è¨€åˆ†å¸ƒ:")
    print("-" * 40)
    
    cursor.execute("""
        SELECT original_language, COUNT(*) as count 
        FROM news_articles 
        GROUP BY original_language 
        ORDER BY count DESC
    """)
    
    for lang, count in cursor.fetchall():
        lang_emoji = {
            'en': 'ğŸ‡ºğŸ‡¸', 'ja': 'ğŸ‡¯ğŸ‡µ', 'ko': 'ğŸ‡°ğŸ‡·', 'zh': 'ğŸ‡¨ğŸ‡³',
            'fr': 'ğŸ‡«ğŸ‡·', 'de': 'ğŸ‡©ğŸ‡ª', 'it': 'ğŸ‡®ğŸ‡¹', 'es': 'ğŸ‡ªğŸ‡¸', 'ru': 'ğŸ‡·ğŸ‡º'
        }.get(lang, 'ğŸŒ')
        print(f"{lang_emoji} {lang}: {count} ç¯‡")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒ æ–°é—»è¯­è¨€æ ‡è¯†ä¿®å¤å·¥å…·")
    print("=" * 60)
    
    fix_language_identification()
    
    print("\nğŸ¯ ä¸‹ä¸€æ­¥:")
    print("   1. è¿è¡Œç¿»è¯‘è„šæœ¬é‡æ–°ç¿»è¯‘éä¸­æ–‡æ–‡ç« ")
    print("   2. éªŒè¯ç¿»è¯‘è´¨é‡")
    print("   3. æµ‹è¯•å‰ç«¯æ˜¾ç¤ºæ•ˆæœ")

if __name__ == "__main__":
    main() 